---
# file: roles/controller/tasks/main.yml

#- seboolean: name=rsync_client state=yes persistent=yes
#  tags: before_config
#  when: ansible_distribution == 'RedHat'

# Dirty hack to upgade /usr/sbin/edeploy before actual upgrade
# and benefit of rsync with attributes feature.
# Useful when running SElinux before J.1.0.0
- name: upgrade edeploy script
  copy: src=edeploy dest=/usr/sbin/edeploy mode=0755
  tags: before_config

# Load balancer part
- name: stop keepalived
  service: name=keepalived state=stopped
  tags: before_config

# Controller part
- name: stop openstack services
  service: name={{ item }} state=stopped
  with_items:
    - "{{ webserver }}"
    - "{{ ceilometer_agent_notification }}"
    - "{{ ceilometer_alarm_evaluator }}"
    - "{{ ceilometer_alarm_notifier }}"
    - "{{ ceilometer_api }}"
    - "{{ ceilometer_collector }}"
    - "{{ cinder_api }}"
    - "{{ cinder_scheduler }}"
    - "{{ cinder_volume }}"
    - "{{ glance_api }}"
    - "{{ glance_registry }}"
    - "{{ heat_api_cfn }}"
    - "{{ heat_api_cloudwatch }}"
    - "{{ heat_api }}"
    - "{{ heat_engine }}"
    - "{{ keystone }}"
    - "{{ neutron_server }}"
    - "{{ neutron_dhcp_agent }}"
    - "{{ neutron_l3_agent }}"
    - "{{ neutron_lbaas_agent }}"
    - "{{ neutron_metadata_agent }}"
    - "{{ neutron_metering_agent }}"
    - "{{ neutron_openvswitch_agent }}"
    - "{{ nova_api }}"
    - "{{ nova_cert }}"
    - "{{ nova_conductor }}"
    - "{{ nova_consoleauth }}"
    - "{{ nova_scheduler }}"
    - "{{ nova_spicehtml5proxy }}"
    - "{{ swift_proxy }}"
  tags: before_config

# MongoDB is upgraded in RHEL7
- name: stop mongodb
  service: name=mongod state=stopped
  tags: before_config
  when: ansible_distribution == 'RedHat'

- name: manage erlang_cookie migration in RabbitMQ
  script: rabbitmq-upgrade.sh {{ erlang_cookie }}
  tags: before_config

# RabbitMQ is upgraded in RHEL7
# This case is when erlang_cookie has been provided and is the same already in place.
- name: stop rabbitmq-server
  service: name=rabbitmq-server state=stopped
  tags: before_config
  when: ansible_distribution == 'RedHat'

- name: stop mysql
  service: name={{ item }} state=stopped
  with_items:
    - mysqld
    - mysql-bootstrap
  tags: before_config
  ignore_errors: yes

- name: stop openvswitch service
  service: name=openvswitch-switch state=stopped
  tags: before_config
  when: ansible_distribution == 'Debian'

- name: edeploy upgrade
  edeploy: command=upgrade version={{ distro }}-{{ version }}
  tags: before_config

- name: reboot the servers
  command: /sbin/reboot -t now
  tags: before_config
  when: ansible_distribution == 'Debian'

- name: Wait for server to come up
  local_action: wait_for host={{ ansible_fqdn }} port=22 delay=120 timeout=900 state=started
  tags: before_config
  when: ansible_distribution == 'Debian'

# Load balancer part

- name: start keepalived
  service: name=keepalived state=started
  tags: before_config
  when: ansible_distribution == 'Debian'

# Controller part

- name: start openvswitch service
  service: name=openvswitch-switch state=started
  tags: before_config
  when: ansible_distribution == 'Debian'

- name: force a galera node to create new cluster
  lineinfile: dest=/usr/lib/systemd/system/mysql-bootstrap.service state=present regexp='^ExecStart=/usr/bin/mysqld_safe' line='ExecStart=/usr/bin/mysqld_safe --wsrep-new-cluster --basedir=/usr'
  tags: before_config
  when: ansible_distribution == 'RedHat' and inventory_hostname == groups['controller'][-1]

- name: bootstrap mysql cluster again
  service: name=mysql-bootstrap state=restarted
  tags: before_config
  when: inventory_hostname == groups['controller'][-1]

- name: start rabbitmq
  service: name=rabbitmq-server state=started
  tags: before_config
  when: inventory_hostname == groups['controller'][-1]

- name: update keystone database
  command: keystone-manage db_sync
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

- name: start keystone service
  service: name={{ keystone }} state=started
  tags: before_config

- name: start swift proxy service
  service: name={{ swift_proxy }} state=started
  tags: before_config

- ini_file: dest=/etc/glance/glance-api.conf
            section=DEFAULT
            option=known_stores
            value=rbd
  tags: before_config

- name: update glance database
  command: glance-manage db_sync
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

- name: start glance services
  service: name={{ item }} state=started
  with_items:
    - "{{ glance_api }}"
    - "{{ glance_registry }}"
  tags: before_config

- name: update cinder database
  command: cinder-manage db sync
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

- name: start cinder services
  service: name={{ item }} state=started
  with_items:
    - "{{ cinder_api }}"
    - "{{ cinder_scheduler }}"
    - "{{ cinder_volume }}"
  tags: before_config

- name: update neutron database
  command: neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

- name: start neutron server service
  service: name={{ neutron_server }} state=started
  tags: before_config

- name: start networking services
  service: name={{ item }} state=started
  with_items:
    - "{{ neutron_dhcp_agent }}"
    - "{{ neutron_l3_agent }}"
    - "{{ neutron_lbaas_agent }}"
    - "{{ neutron_metadata_agent }}"
    - "{{ neutron_metering_agent }}"
    - "{{ neutron_openvswitch_agent }}"
  ignore_errors: yes
  tags: before_config

- name: update heat database
  command: heat-manage --config-file /etc/heat/heat.conf db_sync
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

- name: kill heat-api process
  command: pkill -9 heat-api
  ignore_errors: yes
  tags: before_config
  when: ansible_distribution == 'Debian'

- name: start heat services
  service: name={{ item }} state=started
  with_items:
    - "{{ heat_api_cfn }}"
    - "{{ heat_api_cloudwatch }}"
    - "{{ heat_engine }}"
  tags: before_config

- name: start ceilometer services
  service: name={{ item }} state=started
  with_items:
    - "{{ ceilometer_agent_notification }}"
    - "{{ ceilometer_alarm_evaluator }}"
    - "{{ ceilometer_alarm_notifier }}"
    - "{{ ceilometer_api }}"
    - "{{ ceilometer_collector }}"
  tags: before_config

- name: restart ceilometer-agent-central managed by pacemaker
  command: crm resource cleanup ceilometer-agent-central
  tags: before_config
  when: ansible_distribution == 'Debian' and inventory_hostname == groups['controller'][-1]

- name: restart ceilometer-agent-central managed by pacemaker
  command: pcs resource cleanup openstack-ceilometer-central
  tags: before_config
  when: ansible_distribution == 'RedHat' and inventory_hostname == groups['controller'][-1]

- name: start apache2 service
  service: name={{ webserver }} state=started
  tags: before_config

- name: update nova database
  command: nova-manage db sync
  tags: before_config
  when: inventory_hostname == groups['controller'][0]

# Cap the compute RPC API at a version that will still be understood by your Icehouse compute nodes
- ini_file: dest=/etc/nova.conf
            section=upgrade_levels
            option=compute
            value=icehouse
  tags: before_config

# we don't restart nova-spicehtml5 because it's dropped in J.1.0.0
- name: start nova services
  service: name={{ item }} state=started
  with_items:
    - "{{ nova_api }}"
    - "{{ nova_cert }}"
    - "{{ nova_conductor }}"
    - "{{ nova_consoleauth }}"
    - "{{ nova_scheduler }}"
  tags: before_config

- name: Ensure old puppet ssl files are removed
  file: path=/var/lib/puppet/ssl state=absent
  tags: before_config

# Load balancer part

- name: change mysqlchk port from 9200 to 8200
  replace:
    dest={{ item }}
    regexp='9200'
    replace='8200'
  with_items:
    - "/etc/services"
    - "/etc/xinetd.d/mysqlchk"
    - "/etc/haproxy/haproxy.cfg"
  tags: before_config

- name: restart xinetd
  service: name=xinetd state=restarted
  tags: before_config

- name: start HAproxy service
  service: name=haproxy state=restarted
  tags: before_config

# Controller part

# galera_synced : not master nodes
- name: ensure stop mysql on not master node
  service: name={{ item }} state=stopped
  with_items:
    - mysqld
    - mysql-bootstrap
  tags: galera_synced
  ignore_errors: yes
  when: ansible_distribution == 'RedHat' and inventory_hostname != groups['controller'][-1]

- name: reset cluster state for not master node
  file: path={{ item }} state=absent
  tags: galera_synced
  with_items:
    - /var/lib/mysql/grastate.dat
    - /var/lib/mysql/galera.cache
  when: ansible_distribution == 'RedHat' and inventory_hostname != groups['controller'][-1]

- name: start mysql cluster
  service: name=mysqld state=restarted
  tags: galera_synced
  when: ansible_distribution == 'RedHat' and inventory_hostname != groups['controller'][-1]

# Clean-up nova config by deleting the option, not useful anymore
- ini_file: dest=/etc/nova.conf
            section=upgrade_levels
            option=compute
  tags: after_config

- name: kill neutron-server process
  command: pkill -9 neutron-server
  ignore_errors: yes
  tags: after_config
  when: ansible_distribution == 'Debian'

- name: kill keystone process
  command: pkill -9 keystone
  ignore_errors: yes
  tags: after_config
  when: ansible_distribution == 'Debian'

- name: kill glance-registry process
  command: pkill -9 glance-registry
  ignore_errors: yes
  tags: after_config
  when: ansible_distribution == 'Debian'

- name: restart nova services and neutron-server
  service: name={{ item }} state=restarted
  with_items:
    - "{{ nova_api }}"
    - "{{ nova_cert }}"
    - "{{ nova_conductor }}"
    - "{{ nova_consoleauth }}"
    - "{{ nova_scheduler }}"
    - "{{ neutron_server }}"
    - "{{ keystone }}"
    - "{{ glance_registry }}"
  tags: after_config

- name: restart openstack services
  service: name={{ item }} state=restarted
  with_items:
    - "{{ neutron_dhcp_agent }}"
    - "{{ neutron_l3_agent }}"
    - "{{ neutron_lbaas_agent }}"
    - "{{ neutron_metadata_agent }}"
    - "{{ neutron_metering_agent }}"
    - "{{ neutron_openvswitch_agent }}"
    - "{{ ceilometer_collector }}"
  tags: after_config
  ignore_errors: yes
